
# scrapy框架爬取用户信息
以轮子哥为基点，解析出个人信息，存储到数据库
获取他关注的人和关注他的人，构造这个人的url，请求并解析这个人信息，一直循环下去

# 爬取问题
知乎所有的网页都是使用的动态加载，网页结构还是比较简单 从知乎话题广场开始，爬取一级话题，解析好获得二级话题ID，再爬取二级话题， 每个二级话题下都有三个模块，动态、精华和待回答，开三个进程爬取，解析获得每个问题的ID

# 爬取回答
根据上面爬取问题的ID，爬取答主的名字和答案，每个回答是json格式文件，里面有回答的信息和下一个回答的地址，迭代就好，解析后保存到MongoDB数据库
